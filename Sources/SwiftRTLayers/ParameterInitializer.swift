//******************************************************************************
// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//    https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
import Foundation
import Numerics
import SwiftRTCore

public typealias ParameterInitializer<S: TensorShape, E: StorageElement>
    = (S) -> Tensor<S,E>

/// Returns a function that creates a tensor by initializing
/// all its values to zeros.
@inlinable public func zeros<S,E>() -> ParameterInitializer<S,E>
where S: TensorShape, E.Value: Numeric
{
    { Tensor<S,E>(zeros: $0) }
}

/// Returns a function that creates a tensor by initializing
/// all its values to the provided value.
public func constantInitializer<S,E>(
    value: E.Value
) -> ParameterInitializer<S,E> where S: TensorShape {
    {
        var tensor = Tensor<S,E>(shape: $0)
        fill(&tensor, with: value)
        return tensor
    }
}

/// Returns a function that creates a tensor by initializing it to
/// the provided tensor value. `value` will be broadcasted if needed
public func constantInitializer<S,E>(value: Tensor<S,E>)
-> ParameterInitializer<S,E> where S: TensorShape
{
    {
        guard value.count < $0.elementCount() else { return value }
        // parameters are inherently mutated, so the storage should be dense
        var tensor = Tensor<S,E>(shape: $0)
        copy(from: Tensor<S,E>(repeating: value, to: $0), to: &tensor)
        return tensor
    }
}

/// Returns a function that creates a tensor by performing Glorot (Xavier)
/// uniform initialization for the specified shape, randomly sampling scalar
/// values from a uniform distribution between `-limit` and `limit`,
/// generated by the default random number generator, where limit is
/// `sqrt(6 / (fanIn + fanOut))`, and `fanIn`/`fanOut` represent the number of
/// input and output features multiplied by the receptive field, if present.
public func glorotUniform<S,E>(
    seed: RandomSeed = Context.randomSeed
) -> ParameterInitializer<S,E>
where S: TensorShape, E.Value: Real & BinaryFloatingPoint
{
    { Tensor<S,E>(glorotUniform: $0, seed: seed) }
}

/// Returns a function that creates a tensor by performing Glorot (Xavier)
/// normal initialization for the specified shape, randomly sampling scalar
/// values from a truncated normal distribution centered on `0` with standard
/// deviation `sqrt(2 / (fanIn + fanOut))`, where `fanIn`/`fanOut` represent
/// the number of input and output features multiplied by the receptive
/// field size, if present.
public func glorotNormal<S,E>(
    seed: RandomSeed = Context.randomSeed
) -> ParameterInitializer<S,E>
where S: TensorShape, E.Value: Real & BinaryFloatingPoint
{
    { Tensor<S,E>(glorotNormal: $0, seed: seed) }
}

/// Returns a function that creates a tensor by performing He (Kaiming)
/// uniform initialization for the specified shape, randomly sampling scalar
/// values from a uniform distribution between `-limit`and `limit`, generated
///  by the default random number generator, where limit is
/// `sqrt(6 / fanIn)`, and `fanIn` represents the number of input features
/// multiplied by the receptive field, if present.
public func heUniform<S,E>(
    seed: RandomSeed = Context.randomSeed
) -> ParameterInitializer<S,E> where
S: TensorShape, E.Value: Real & BinaryFloatingPoint
{
    { Tensor<S,E>(heUniform: $0, seed: seed) }
}

/// Returns a function that creates a tensor by performing He (Kaiming)
/// normal initialization for the specified shape, randomly sampling scalar
/// values from a truncated normal distribution centered on `0` with standard
/// deviation `sqrt(2 / fanIn)`, where `fanIn` represents the number of input
/// features multiplied by the receptive field size, if present.
public func heNormal<S,E>(
    seed: RandomSeed = Context.randomSeed
) -> ParameterInitializer<S,E> where
    S: TensorShape, E.Value: Real & BinaryFloatingPoint
{
    { Tensor<S,E>(heNormal: $0, seed: seed) }
}

/// Returns a function that creates a tensor by performing LeCun uniform
/// initialization for the specified shape, randomly sampling scalar values
/// from a uniform distribution between `-limit` and `limit`, generated by the
/// default random number generator, where limit is
/// `sqrt(3 / fanIn)`, and `fanIn` represents the number of input features
/// multiplied by the receptive field, if present.
public func leCunUniform<S,E>(
    seed: RandomSeed = Context.randomSeed
) -> ParameterInitializer<S,E>
where S: TensorShape, E.Value: Real & BinaryFloatingPoint
{
    { Tensor<S,E>(leCunUniform: $0, seed: seed) }
}

/// Returns a function that creates a tensor by performing LeCun normal
/// initialization for the specified shape, randomly sampling scalar values
/// from a truncated normal distribution centered on `0` with standard
/// deviation `sqrt(1 / fanIn)`, where `fanIn` represents the number of input
/// features multiplied by the receptive field size, if present.
public func leCunNormal<S,E>(
    seed: RandomSeed = Context.randomSeed
) -> ParameterInitializer<S,E>
where S: TensorShape, E.Value: Real & BinaryFloatingPoint
{
    { Tensor<S,E>(leCunNormal: $0, seed: seed) }
}

/// Returns a function that creates a tensor by initializing all its values
/// randomly from a truncated Normal distribution. The generated values
/// follow a Normal distribution with mean `mean` and standard deviation
///  `standardDeviation`, except that values whose magnitude is more
/// than two standard deviations from the mean are dropped and resampled.
///
/// - Parameters:
///   - mean: Mean of the Normal distribution.
///   - standardDeviation: Standard deviation of the Normal distribution.
///
///- Returns: A truncated normal parameter initializer function.
public func truncatedNormalInitializer<S,E>(
    mean: Tensor<S,E>? = nil,
    std: Tensor<S,E>? = nil,
    layout: Layout = Layout.defaultValue,
    seed: RandomSeed = Context.randomSeed
) -> ParameterInitializer<S,E>
where S: TensorShape, E.Value: Real & BinaryFloatingPoint
{
    {
        // TODO: which element init is being called??
        Tensor<S,E>(randomTruncatedNormal: $0,
                    mean: mean ?? Tensor<S,E>(0, layout: layout),
                    std: std ?? Tensor<S,E>(1, layout: layout),
                    layout: layout,
                    seed: seed)
    }
}
